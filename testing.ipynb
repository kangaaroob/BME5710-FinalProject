{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d03dfd8",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe29d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.image.psnr import PeakSignalNoiseRatio\n",
    "from torchmetrics.image.ssim import StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82217412",
   "metadata": {},
   "source": [
    "Resource check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "121f95f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available: mps\n"
     ]
    }
   ],
   "source": [
    "# ON MACOS\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print('Device available:', device)\n",
    "\n",
    "# ON WINDOWS\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('Device available:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86f9ac",
   "metadata": {},
   "source": [
    "Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db09e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 240\n"
     ]
    }
   ],
   "source": [
    "# Loading TIFF images for Super-resolution\n",
    "class TIFFDataset(Dataset):\n",
    "    def __init__(self, high_res_dir, low_res_dir, transform=None):\n",
    "        self.high_res_dir = high_res_dir\n",
    "        self.low_res_dir = low_res_dir\n",
    "        self.transform = transform\n",
    "        self.filenames = sorted([f for f in os.listdir(high_res_dir) if f.endswith('.tif')])\n",
    "    \n",
    "    # Get the number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    # Get the sample at the given index\n",
    "    def __getitem__(self, idx):\n",
    "        high_res_path = os.path.join(self.high_res_dir, self.filenames[idx])\n",
    "        low_res_path = os.path.join(self.low_res_dir, self.filenames[idx])\n",
    "\n",
    "        # Load images\n",
    "        high_res = Image.open(high_res_path)\n",
    "        low_res = Image.open(low_res_path)\n",
    "\n",
    "        # Resize low-res to 128x128 (ensuring correct input size)\n",
    "        low_res = low_res.resize((128, 128), Image.BICUBIC)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            high_res = self.transform(high_res)\n",
    "            low_res = self.transform(low_res)\n",
    "\n",
    "        return low_res, high_res  # Returning input-output pairs\n",
    "\n",
    "# Define a transform to convert images to PyTorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "flip = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define a transform to convert images to PyTorch tensors with normalization\n",
    "normalize = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# normalize_flip = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "#     transforms.RandomHorizontalFlip(p=1.0)\n",
    "# ])\n",
    "\n",
    "# Create the dataset for training images\n",
    "train_dataset = TIFFDataset('data/train/high-res', 'data/train/low-res', transform=transform)\n",
    "# Create the dataset for training images with flipping\n",
    "# train_dataset_flip = TIFFDataset('data/train/high-res', 'data/train/low-res', transform=flip)\n",
    "\n",
    "# Combine the datasets\n",
    "# train_dataset = torch.utils.data.ConcatDataset([train_dataset, train_dataset_flip])\n",
    "\n",
    "# Function to create data loader\n",
    "def create_loader(dataset, batch_size):\n",
    "    torch.manual_seed(0)  # For reproducibility\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print dataset size\n",
    "dataset_size = len(train_dataset)\n",
    "print('Number of images in the dataset:', dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251e0ce",
   "metadata": {},
   "source": [
    "Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92ac0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        self.gelu = nn.GELU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        x = self.gelu(self.conv1(x))\n",
    "        x = self.gelu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6168f76",
   "metadata": {},
   "source": [
    "Training Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "acba960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, criterion, train_loader, num_epoch):\n",
    "    avg_train_losses = []\n",
    "\n",
    "    for epoch in range(num_epoch):  # Loop over the dataset multiple times\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, (x_tr_batch, y_tr_batch) in enumerate(train_loader):  # Loop over mini-batches\n",
    "            x_tr_batch, y_tr_batch = x_tr_batch.to(device), y_tr_batch.to(device)\n",
    "\n",
    "            # Upsample low-resolution input to 256x256\n",
    "            # x_tr_batch = torch.nn.functional.interpolate(x_tr_batch, scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "            opt.zero_grad()  # Delete previous gradients\n",
    "            y_hat_tr_batch = model(x_tr_batch)  # Forward pass\n",
    "            loss = criterion(y_hat_tr_batch, y_tr_batch)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            opt.step()  # Update weights\n",
    "            total_train_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Iteration {i+1}, Loss: {loss.item():.6f}')\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)  # Compute average loss\n",
    "        avg_train_losses.append(avg_train_loss)  # Store average loss\n",
    "\n",
    "    # Plot training loss\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(range(1, num_epoch + 1), avg_train_losses, label='training loss')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_yscale('log')  # Log scale for better visualization\n",
    "    ax.set_title('training loss')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4019070",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fda96137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 10, Loss: 0.009769\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAHWCAYAAACRyIrfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALFBJREFUeJzt3QmYneP9P/47i8QaIbbEkthKxr6MvV87xWWt4kut39Iy1FJKS9Vyqa3UkrHWV1CK2r52YleNirWIXRrUEnsQIpLzvz73/zrzyyaZTGZyZuZ+va7rmDnPeZ7n3Oe5z8T73Ofz3E+XSqVSSQAA0Ml1rXUDAABgVhB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAHakQEDBqR99tmnRdtutNFG+dbR2g0wqwi+ADPgH//4RzrhhBPSZ599VuumADCDus/oBgClB98TTzwxj2727t271ff/yiuvpK5dWzYmce+997Z6ewA6E8EXoI1MmDAhffvtt2n22Wdv9jY9e/Zs8fP16NGjxdsClECpA0AzRYnDUUcdlX9fcsklU5cuXfLt3//+d14Wvx988MHp6quvTiussEIOsXfffXd+7I9//GNab731Up8+fdIcc8yR1lhjjXTDDTdMt1Z28ODBeb+PPfZYOuKII9KCCy6Y5pprrrTjjjumDz/8cJo1vg899FDe9vrrr0+nnHJKWmyxxXII33TTTdPrr78+xXM3NjampZZaKrdvrbXWSo8++uhM1Q2/+eab6Sc/+Umaf/7505xzzpnWWWeddMcdd0yx3vnnn5+PV6wz33zzpTXXXDNdc801TY9/8cUX6bDDDsvHJo7pQgstlDbffPP09NNPt6hdQLmM+AI000477ZReffXV9Ne//jX96U9/SgsssEBeHmG06oEHHshBMwJwPB5hLZx77rlpu+22S3vssUceBb722mtzKLz99tvTNttsM93nPuSQQ3Io/P3vf5+D9jnnnJOf47rrrpvutqeddlounzjyyCPT559/ns4444zcjn/+859N61x44YV5fz/84Q/T4Ycfnp9jhx12yM8ZgXlGffDBBznojxkzJv3yl7/Mgf+KK67IxyACfwT3cOmll+bHd95553TooYemb775Jv3rX//Kbdt9993zOr/4xS/yNtG+urq69PHHH6e///3v6aWXXkqrr776DLcNKFgFgGY788wzK/FP54gRI6Z4LJZ37dq18uKLL07x2JgxYya5/+2331ZWXHHFyiabbDLJ8v79+1f23nvvpvuXX3553u9mm21WmTBhQtPyww8/vNKtW7fKZ5991rRsww03zLeqBx98MG87cODAytixY5uWn3vuuXn5888/n+/HY3369KnU19dXxo0b17Te4MGD83oT7/P7TN7uww47LG/76KOPNi374osvKksuuWRlwIABlfHjx+dl22+/fWWFFVaY5r7nnXfeSkNDw3TbADA9Sh0AWtGGG26YRyUnF+UDVZ9++mkeeY3R1eZ+XX/AAQfksoWq2Hb8+PFp5MiR09123333naT+N7atliKEJ598Mo+i7r///ql79//3RWCMCseIb0vceeeduVxigw02aFo299xz59cRo8nDhw/Py+IEwXfeeScNGzbse/cV68QI8LvvvtuitgBUCb4ArShqf6cmShqixjVqbKPmNcojorwgAnBzLLHEEpPcrwbSCNEzu201PC+zzDKTrBchuFqqMaNin8stt9wUywcOHDjJcx599NE5EEdIXnbZZVNDQ0OuZ55YlGa88MILafHFF8/rRa11NbQDzAjBF6AVTTyyWxUniUVta4TeCy64II+GDhkyJNew/v8VEtPXrVu3qS5vzvYzs21biyAcU7hFzXOMDt944435Z9QyV+2yyy456MZJcP369UtnnnlmPhnurrvuqmnbgY5H8AWYAROXGzRXhLkIvffcc0/ab7/90lZbbZU222yz1F70798//5x8pofvvvuuacaKluwzAu3kXn755UmeM8QsFbvuumu6/PLL01tvvZVP9otZKOJEt6q+ffumgw46KN1yyy1pxIgR+WS5WAdgRgi+ADMgQlqYkSu3xYhrBOaoya2KQBkhrj2I6cMiSMYMCxF2q2JatuaUUkzN1ltvnZ544ok0dOjQpmVfffVVuuSSS3L5RLUOOmqLJxa1yPFYjEaPGzcuH7PJy0FiOrMY+R07dmyL2gaUy3RmADMg5t8Nxx57bNptt93SbLPNlrbddtumQDw1MYJ59tlnpx/96Ee5vGHUqFF5ztyoqY2pu2otwmbUzcaUaZtsskkuLYhgHnMIL7300i0a5T7mmGPytG8xuh3TlUVdc0xnFqO1MQJevTrdFltskRZZZJG0/vrrp4UXXjhPUTZo0KB8zOaZZ578ASOmU4vpzlZZZZVcD3zfffflk+HOOuusNjgaQGcm+ALMgPr6+nTyySeniy66KF+cIq7OFmFuWsE3wuRll12W59ONCzHECXCnn356DpftIfiGmCM3RlkjTMZ8vxEyb7311hxaZ+TKc1URYuPyznHyWtTmRtnCyiuvnG677bZJ5i3++c9/nkeW44PBl19+mUNuPOdxxx2XH4+LWkSJQ1yO+aabbsrHOz4wRK30gQce2KrHAOj8usScZrVuBADtT4TMmH0iLtwRZRAAHZ0aXwDyiOzk4yBXXnll+uSTT1p8yWKA9saILwDpoYceypcqjssox4lucWGNKM+I6caeeuqpSS6AAdBRqfEFIM+0EBeIOO+88/Iob5yMttdee+W6ZKEX6CyM+AIAUAQ1vgAAFEHwBQCgCGp8pzOVz7vvvpsnUW/JBO4AALStqNr94osv8hUdqxfH+T6C7zRE6I2TPQAAaN/efvvtfBGcaRF8pyFGeqsHslevXrVuTqcwbty4fAWmuExpXOqVjkcfdmz6r+PThx2fPmxdo0ePzgOV1dw2LYLvNFTLGyL0Cr6t98celyCN4+mPvWPShx2b/uv49GHHpw/bRnPKUp3cBgBAEQRfAACKIPgCAFAENb4AQLszfvz4XAvbGcXr6t69e/rmm2/y62T6unXrlo/ZzE4vK/gCAO3Kl19+md555508P2tnFK9rkUUWybNGuU5A88UJgX379k09evRILSX4AgDtRoyARuiNkLPgggt2ymAYF8iKcD/33HNP94ILpPxB4dtvv00ffvhhGjFiRFp22WVbfNwEXwCgXZUBRNCJ0DvHHHOkziiCbwS52WefXfBtpngvxNRvI0eObDp2LeFoAwDtTmcc6WXmtMaHBMEXAIAiFBF8d9xxxzTffPOlnXfeudZNAQCgRooIvoceemi68sora90MAIBmGTBgQDrnnHOavf5DDz2Uy0M+++yzNm3X4MGDU+/evVNHVUTw3WijjdI888xT62YAAJ04axx22GGttr9hw4alAw44oNnrr7feeum9995L8847b6u1oTOqefB95JFH0rbbbpv69euXP6nccsstU6zT2NiYP/nEGXxrr712euKJJ2rSVgCAlorZKr777rtmrRuzWsSUbs0Vc9vG3MBOCmzn05l99dVXaZVVVkn77bdf2mmnnaZ4/LrrrktHHHFEuuiii3LojWH/LbfcMr3yyitpoYUWyuusuuqqU30j3XvvvTlQN9fYsWPzrWr06NFNU6t01qvHzGrV4+h4dlz6sGPTfx1fZ+/D6nRmMeVX3OL3r8fV5upmc8zWrVlBct99900PP/xwvp177rl52RtvvJH+/e9/p0033TTdfvvt6fjjj0/PP/98uvvuu9Niiy2WR4efeuqpnIMGDhyYTjnllLTZZps17XOppZbKpZpxq1657OKLL0533nlnzjeLLrpoOvPMM9N2223XVOoQz/Xxxx/nUoQoSYj89Ne//jX/jItlrL/++ul///d/80UgQmSnX/3qV+mqq67K+/+f//mf9P7776fPP/883XzzzVN9rdEnE/8MF154YTr77LPzcyy55JLpt7/9bdpzzz3zY9F/J510Urr88svTBx98kPr06ZN+/OMfNx2n2DayXWwbo9UbbLBB+tvf/va9zx37i/dItLdqRv4Wah58t9pqq3z7PnEg999///ymChGA77jjjtxxxxxzTF727LPPtkpbTj311HTiiSdOsTzeYDPyqYvpGzJkSK2bwEzShx2b/uv4OmsfxmVpY+QyLvAQ87V+/e34tO7Zj9ekLUOPWCfN0eP/BazvE8HupZdeSnV1dek3v/lNXhYhbsyYMfn3o48+Op188sn52+sIpXGBjs033zwdd9xxqWfPnunaa69N22+/ff5Ge/HFF28KeXFJ4+ogXIiMErcI0ZdcckkOl//617/yCfzV5/riiy/ytF+xbSw744wz0gUXXJCX/fznP8+B+9JLL83r/vGPf0xXX311GjRoUPrBD36QM1Z88/7DH/5wkuedWOw3wmf18Qj1hx9+ePrDH/6Qyz3uueeeHKDnn3/+vJ//+7//S3/605/SZZddlpZffvk0atSo9MILL+Ttn3nmmRzs43nXWmutXJ88dOjQ733u/H74+utcLTDxgGf1tXeI4Dst8QLj01D1TRSi4+ITURyY1hbPE5+KquLAxxtwiy22SL169Wr15ytRfCqLf6zjDz4moqbj0Ycdm/7r+Dp7H0awitG/uKpZlDh2/7Z5pQFtYZ5e86Q5e0w/KkVGiAGyCLtxVbGq6qBZhN4ItlVLLLFEWmmllfL5RzGivNpqq6W77rorj9o2NDQ05Z14/RPnjxgEjG/IQ4z2xghwBO4f/ehHTc8V+4xtYtt4r0RAXnrppfNjhxxySG5LdZ9//vOfc/bZfffd8/3Y3/33358/fHxf7on9Rpurj8eI7d57792Un1ZfffU8IBnLt9lmm/TRRx/lEeYYmY736worrJA23njjvG6MTs8111zpJz/5SdO5WDHiO633RlzI4r/+678muYDF9wXlDhd842DFpQsXXnjhSZbH/ZdffrnZ+4mg/Nxzz+WvE+LrhRhCX3fddadYLz51xW1y0VGd8R+XWnJMOz592LHpv46vs/Zh/H8/glUEv7jN1XO2NPykLdt1qUNVtd1V1d9jNHPi5RHUfve736X77rsvn5AWo5cxkhmBf+L1Jt9flIZW71cDbmSl6rGqPmf1FmF44iDer1+/POIaj0U5Q5QeRBnpxNuuscYaebT5+y4WMfG6IYJ3nIQ38foRXqOUIZbtsssu+fdlllkmB/Stt946n9sV4TpKV/v379/0WNxiCtrv+5Y99hfHZPL3/oz8HbTr4Nta4o0FAHQ8EXSaM+ransWo5sSOOuqoXEYZpQZRYhCjmHGtgfime1omD3hxbCautW3O+pVKJc1K8c15nJcVWSy+qTjooIPyaHXUQ0d4f/rpp/NIdxyPKOE44YQT8owWbTVlWs1ndZiWBRZYIBcvxyeSicX9qP8BAGgPYlaFGK1ujn/84x+5vCBGN6PkITJNnAg3K80777z5G/QImVXR/giiMyJOzHvssccmWRb3o965KoJ9jPKed955OeRGuWqc6Bdi5De+mY9a5KhXjuPwwAMPpLbSvb2/iWLIPepNdthhh7wsPtnE/YMPPrjWzQMAyOLEtX/+8585uEV9cpzc9X3iq/3bbrstz24QA3xR9jCtkdu2csghh+QT+6M9ceLZ+eefnz799NMZKu+I0esoZ4g65Qiw8bpuuummpm/bY3aJCNRRUhElDH/5y19yEI4Shzgx7s0338w1u3GCXsxYEcdhueWW67zBN87afP3115vujxgxIhdFxxsmir+jWDqKptdcc81cIxNTXkStbnWWBwCAWjvyyCNzXomRzqjXjTzzfc4666y0zz775FrY+HY7Zn2YkRO0WsvRRx+dpy/ba6+9cgCPWt2ou514qrDpiYHJqOGNso2YoSGmM4upy2KGhxAlC6eddlrOcxGAY4Q7wnFMaxaPRUiO8oY4cS3qkWP6tTgBrq10qczqYo/JxJB39ey+icWbJz4lhJhmI+pBonNizt4YKo9PDm0t3oTxVUAUgJvVoXXEGabxiS6K2zvjSRkl0Icdm/7r+Dp7H0YAitAYAWriM/c7kxjVjIwR2eL7TiKrVbsGDhyYR3Bj9oeO8t6YkbxW8xHf+EQwvewdZQ1KGwAAWs/IkSPzSWUbbrhhvoBXDDRGsKxOb9YZtZ+PGQAAzDJdu3bN367X19fnq7rFCWdRmxujvp1VzUd8AQCY9RZffPEpZmTo7Iz4AgBQBMEXAGh3anzuPZ30PSH4AgDtRnUqreldxYzyjBkzJv+cmdlM1PgCAO1GXMkrLnTw4Ycf5oDTnqb7as1pwyLYx/RcnfH1tcVIb4TeUaNG5bl/Z2Se4ckJvgBAuxFXDevbt2+eVium2+qsQS4uchFXMJuRq6SVrnfv3vnyzjND8J2KxsbGfGvuNbcBgNbTo0ePfBWvzlruEBcheeSRR/KlejvjRUjaQhynmRnprRJ8p6KhoSHfqlcCAQBmrSgB6KxXbosA99133+XXJ/jOWgpLAAAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHynorGxMdXV1aX6+vpaNwUAgFYi+E5FQ0NDGj58eBo2bFitmwIAQCsRfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBN+paGxsTHV1dam+vr7WTQEAoJUIvlPR0NCQhg8fnoYNG1brpgAA0EoEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHynorGxMdXV1aX6+vpaNwUAgFYi+E5FQ0NDGj58eBo2bFitmwIAQCsRfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQTfqWhsbEx1dXWpvr6+1k0BAKCVCL5T0dDQkIYPH56GDRtW66YAANBKBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQTfqWhsbEx1dXWpvr6+1k0BAKCVCL5T0dDQkIYPH56GDRtW66YAANBKBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARWhR8H377bfTO++803T/iSeeSIcddli65JJLWrNtAABQ2+C7++67pwcffDD//v7776fNN988h99jjz02nXTSSa3XOgAAqGXwfeGFF9Jaa62Vf7/++uvTiiuumP7xj3+kq6++Og0ePLi12gYAALUNvuPGjUs9e/bMv993331pu+22y78vv/zy6b333mu91gEAQC2D7worrJAuuuii9Oijj6YhQ4akH/3oR3n5u+++m/r06dNabQMAgNoG39NPPz1dfPHFaaONNkr//d//nVZZZZW8/NZbb20qgQAAgPake0s2isD70UcfpdGjR6f55puvafkBBxyQ5pxzztZsHwAA1G7E9+uvv05jx45tCr0jR45M55xzTnrllVfSQgst1DotAwCAWgff7bffPl155ZX5988++yytvfba6ayzzko77LBDuvDCC1uzfQAAULvg+/TTT6cf/vCH+fcbbrghLbzwwnnUN8Lweeed1zotAwCAWgffMWPGpHnmmSf/fu+996addtopde3aNa2zzjo5AAMAQKcIvssss0y65ZZb8qWL77nnnrTFFlvk5aNGjUq9evVq7TYCAEBtgu/xxx+fjjzyyDRgwIA8fdm6667bNPq72mqrzXyrAACgPUxntvPOO6cNNtggX6WtOodv2HTTTdOOO+7Ymu0DAIDaBd+wyCKL5Ns777yT7y+22GIuXgEAQOcqdZgwYUI66aST0rzzzpv69++fb717904nn3xyfgwAADrFiO+xxx6bLrvssnTaaael9ddfPy/7+9//nk444YT0zTffpFNOOaW12wkAALM++F5xxRXpz3/+c9puu+2alq288spp0UUXTQcddJDgCwBA5yh1+OSTT9Lyyy8/xfJYFo8BAECnCL4xk8OgQYOmWB7LYuS3o2tsbEx1dXWpvr6+1k0BAKCWpQ5nnHFG2mabbdJ9993XNIfv0KFD8wUt7rzzztTRNTQ05Nvo0aPzCXwAABQ64rvhhhumV199Nc/Z+9lnn+VbXLb4xRdfTFdddVXrtxIAAGo1j2+/fv2mOIntueeey7M9XHLJJTPbLgAAqP2ILwAAdDSCLwAARRB8AQAowgzV+MYJbNMSJ7kBAECHD77Tm9orHt9rr71mtk0AAFDb4Hv55Ze3fgsAAGAWUOMLAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+U9HY2Jjq6upSfX19rZsCAEArEXynoqGhIQ0fPjwNGzas1k0BAKCVCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAiCLwAARRB8AQAoguALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIAiCL4AABRB8AUAoAidPvi+/fbbaaONNkp1dXVp5ZVXTn/7299q3SQAAGqge+rkunfvns4555y06qqrpvfffz+tscYaaeutt05zzTVXrZsGAMAs1OmDb9++ffMtLLLIImmBBRZIn3zyieALAFCYmpc6PPLII2nbbbdN/fr1S126dEm33HLLFOs0NjamAQMGpNlnnz2tvfba6YknnmjRcz311FNp/PjxafHFF2+FlgMA0JHUfMT3q6++Squsskrab7/90k477TTF49ddd1064ogj0kUXXZRDb5QtbLnllumVV15JCy20UF4nyhi+++67Kba99957c6AOMcq71157pUsvvfR72zJ27Nh8qxo9enT+OW7cuHxj5lWPo+PZcenDjk3/dXz6sOPTh61rRo5jl0qlUkntRIz43nzzzWmHHXZoWhZht76+Pg0aNCjfnzBhQh6xPeSQQ9IxxxzTrP1GmN18883T/vvvn/bcc8/vXe+EE05IJ5544hTLr7nmmjTnnHO26DUBANB2xowZk3bffff0+eefp169erXvEd9p+fbbb3N5wm9+85umZV27dk2bbbZZGjp0aLP2Ebl+n332SZtsssk0Q2+I54nR5YlHfCNkb7HFFtM9kDT/U9mQIUPyB5HZZput1s2hBfRhx6b/Oj592PHpw9ZV/Ya+Odp18P3oo49yTe7CCy88yfK4//LLLzdrH4899lgul4ipzKr1w1dddVVaaaWVpli3Z8+e+Ta5eFN6Y7Yux7Tj04cdm/7r+PRhx6cPW8eMHMN2HXxbwwYbbJDLIwAAKFvNZ3WYlph6rFu3bumDDz6YZHncj6nJAACgUwTfHj165AtO3H///U3LYvQ27q+77ro1bRsAAB1LzUsdvvzyy/T666833R8xYkR69tln0/zzz5+WWGKJfLLZ3nvvndZcc8201lpr5enMYgq0fffdt6btBgCgY6l58H3yySfTxhtv3HS/OqtChN3BgwenXXfdNX344Yfp+OOPz5ccjjl777777ilOeAMAgHYdfDfaaKM85di0HHzwwfkGAACdssYXAABai+ALAEARBF8AAIog+AIAUATBFwCAIgi+AAAUQfAFAKAIgu9UNDY2prq6ulRfX1/rpgAA0FkuYNEeNTQ05Nvnn3+eevfunUaPHl3rJnUa48aNS2PGjMnHdLbZZqt1c2gBfdix6b+OTx92fPqwdVVz2vQuiBYE32n44osv8s/FF1+81k0BAGA6uW3eeeed1iqpS6U58bhQEyZMSO+++26aZ555UpcuXWrdnE7zqSw+SLz99tupV69etW4OLaAPOzb91/Hpw45PH7auiLIRevv165e6dp12Fa8R32mIg7fYYovVuhmdUvyh+2Pv2PRhx6b/Oj592PHpw9YzvZHeKie3AQBQBMEXAIAiCL7MUj179ky///3v8086Jn3Ysem/jk8fdnz6sHac3AYAQBGM+AIAUATBFwCAIgi+AAAUQfAFAKAIgi8zpbGxMQ0YMCDNPvvsae21105PPPHENK9NftJJJ6Wll146r7/KKquku+++e4r1/vOf/6Sf/vSnqU+fPmmOOeZIK620UnryySfb+JWUq7X7cPz48el3v/tdWnLJJXP/xbonn3xys66hzox75JFH0rbbbpuvWBRXmLzlllumu81DDz2UVl999XxG+TLLLJMGDx48U+8L2lf/nXrqqam+vj5fdXShhRZKO+ywQ3rllVfa8FWUra3+BqtOO+20vN/DDjuslVteJsGXFrvuuuvSEUcckadkefrpp3MI2nLLLdOoUaOmuv5xxx2XLr744nT++een4cOHp1/84hdpxx13TM8880zTOp9++mlaf/3102yzzZbuuuuuvN5ZZ52V5ptvvln4ysrRFn14+umnpwsvvDANGjQovfTSS/n+GWeckbeh9X311Ve53yKoNseIESPSNttskzbeeOP07LPP5v+Z/uxnP0v33HNPi98XtK/+e/jhh1NDQ0N6/PHH05AhQ/IH1i222CI/Fx2jD6uGDRuW/81deeWV26DlhYrpzKAl1lprrUpDQ0PT/fHjx1f69etXOfXUU6e6ft++fSuDBg2aZNlOO+1U2WOPPZruH3300ZUNNtigDVtNW/fhNttsU9lvv/2muQ5tI/5Jv/nmm6e5zq9//evKCiusMMmyXXfdtbLlllu2+H1B++q/yY0aNSrv++GHH261ttL2ffjFF19Ull122cqQIUMqG264YeXQQw9tkzaXxogvLfLtt9+mp556Km222WZNy7p27ZrvDx06dKrbjB07Nn9tOrH4Kvzvf/970/1bb701rbnmmuknP/lJ/oputdVWS5deemkbvpJytVUfrrfeeun+++9Pr776ar7/3HPP5ce32mqrNnstNF/07cR9HmI0t9rnLXlf0H76b2o+//zz/HP++edv8/bRen0Yo/YxMjz5uswcwZcW+eijj3It58ILLzzJ8rj//vvvT3Wb+MM+++yz02uvvZYmTJiQv4K76aab0nvvvde0zptvvpm/Jl922WXz1z4HHnhg+uUvf5muuOKKNn9NpWmrPjzmmGPSbrvtlpZffvlcshIfXuKrvD322KPNXxPTF307tT4fPXp0+vrrr1v0vqD99N/k4u80/v6ihGzFFVechS1lZvrw2muvzWVGUa9N6xJ8mWXOPffcHGgjEPXo0SMdfPDBad99982jSRP/Ix0F/3/4wx9yYDrggAPS/vvvny666KKatp3m9+H111+frr766nTNNdfkf7jjQ8sf//hHH16gBmLU8IUXXshBio7h7bffToceemj+d3Tyb9iYeYIvLbLAAgukbt26pQ8++GCS5XF/kUUWmeo2Cy64YD7bNU4EGDlyZHr55ZfT3HPPnZZaaqmmdfr27Zvq6uom2W7gwIHprbfeaqNXUq626sOjjjqqadQ3ZuTYc8890+GHH27kop2Ivp1an/fq1SuXrbTkfUH76b+JxQfT22+/PT344INpscUWm8UtpaV9GKVGcSJpDAJ179493+KExfPOOy//Ht/I0HKCLy0So31rrLFGruWceLQ27q+77rrT3DY+wS666KLpu+++SzfeeGPafvvtmx6Lr+Mmn3YnakX79+/fBq+ibG3Vh2PGjJlkBDhEkIp9U3vRtxP3eYiSlWqfz8z7gtr3X4hzrCL03nzzzemBBx7IUwvScfpw0003Tc8//3ye8aF6i3Nfolwsfo9/T5kJtT67jo7r2muvrfTs2bMyePDgyvDhwysHHHBApXfv3pX3338/P77nnntWjjnmmKb1H3/88cqNN95YeeONNyqPPPJIZZNNNqksueSSlU8//bRpnSeeeKLSvXv3yimnnFJ57bXXKldffXVlzjnnrPzlL3+pyWvs7NqiD/fee+/KoosuWrn99tsrI0aMqNx0002VBRZYIJ/JTOuLM7+feeaZfIt/0s8+++z8+8iRI/Pj0X/Rj1Vvvvlm/ps66qijKi+99FKlsbGx0q1bt8rdd9/d7PcF7bv/DjzwwMq8885beeihhyrvvfde023MmDE1eY2dXVv04eTM6tB6BF9myvnnn19ZYoklKj169MhTIEUwmvgPNUJQVfwjPHDgwPw/1D59+uR/CP7zn/9Msc/bbrutsuKKK+b1ll9++coll1wyy15PiVq7D0ePHp3/gY59zj777JWlllqqcuyxx1bGjh07S19XKR588MH8P9vJb9V+i5/Rj5Nvs+qqq+Y+j/65/PLLZ+h9Qfvuv6ntL25T62fa79/gxATf1tMl/jMzI8YAANARqPEFAKAIgi8AAEUQfAEAKILgCwBAEQRfAACKIPgCAFAEwRcAgCIIvgAAFEHwBWCqHnroodSlS5f02Wef1bopAK1C8AUAoAiCLwAARRB8AdqpCRMmpFNPPTUtueSSaY455kirrLJKuuGGGyYpQ7jjjjvSyiuvnGafffa0zjrrpBdeeGGSfdx4441phRVWSD179kwDBgxIZ5111iSPjx07Nh199NFp8cUXz+sss8wy6bLLLptknaeeeiqtueaaac4550zrrbdeeuWVV5oee+6559LGG2+c5plnntSrV6+0xhprpCeffLJNjwtASwm+AO1UhN4rr7wyXXTRRenFF19Mhx9+ePrpT3+aHn744aZ1jjrqqBxmhw0blhZccMG07bbbpnHjxjUF1l122SXttttu6fnnn08nnHBC+t3vfpcGDx7ctP1ee+2V/vrXv6bzzjsvvfTSS+niiy9Oc8899yTtOPbYY/NzRKDt3r172m+//Zoe22OPPdJiiy2Wnz+e75hjjkmzzTbbLDk+ADOqS6VSqczwVgC0qRiJnX/++dN9992X1l133ablP/vZz9KYMWPSAQcckEdar7322rTrrrvmxz755JMcQiPYRuCNUPrhhx+me++9t2n7X//613mUOIL0q6++mpZbbrk0ZMiQtNlmm03RhhhVjueINmy66aZ52Z133pm22Wab9PXXX+dR5hjlPf/889Pee+89S44LwMww4gvQDr3++us54G6++eZ5BLZ6ixHgN954o2m9iUNxBOUIsjFyG+Ln+uuvP8l+4/5rr72Wxo8fn5599tnUrVu3tOGGG06zLVFKUdW3b9/8c9SoUfnnEUcckcN4BOfTTjttkrYBtDeCL0A79OWXX+afMTobAbV6Gz58eFOd78yKuuHmmLh0IeqKq/XHIconYvQ4RoEfeOCBVFdXl26++eZWaR9AaxN8AdqhCJBxstlbb72VTzib+BYnolU9/vjjTb9/+umnuXxh4MCB+X78fOyxxybZb9z/wQ9+kEd6V1pppRxgJ64ZbonYX9QfR0nFTjvtlC6//PKZ2h9AW+neZnsGoMViloQjjzwyB8oIpxtssEH6/PPPc3CNutr+/fvn9U466aTUp0+ftPDCC+eT0BZYYIG0ww475Md+9atfpfr6+nTyySfnOuChQ4emQYMGpQsuuCA/HrM8RG1unKwWJ7fFrBEjR47MZQxRIzw9UecbJ9ftvPPOeeaJd955J5/k9uMf/7iNjw5Aywi+AO1UBNaYqSFmd3jzzTdT79690+qrr55++9vfNpUaRF3toYcemut2V1111XTbbbelHj165Mdi3euvvz4df/zxeV9RnxtBeZ999ml6jgsvvDDv76CDDkoff/xxWmKJJfL95ohR49gmZob44IMPcuiOEd8TTzyxjY4IwMwxqwNAB1SdcSHKGyIQAzB9anwBACiC4AsAQBGUOgAAUAQjvgAAFEHwBQCgCIIvAABFEHwBACiC4AsAQBEEXwAAiiD4AgBQBMEXAIBUgv8PsaZIMhYfMEUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 15  # Number of complete images in each batch\n",
    "lr = 1e-3  # Learning rate\n",
    "num_epoch = 1  # Epochs\n",
    "\n",
    "# Model, criterion, and optimizer\n",
    "train_loader = create_loader(train_dataset, batch_size)\n",
    "model = testNet().to(device)  # Pick a model and move to GPU/CPU\n",
    "opt = optim.Adam(model.parameters(), lr=lr)  # Pick an optimizer\n",
    "criterion = nn.MSELoss()  # Pick a loss function\n",
    "\n",
    "# Train the model\n",
    "train_model(model, opt, criterion, train_loader, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8890f88",
   "metadata": {},
   "source": [
    "MAC Stupidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f64077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testNet(\n",
       "  (gelu): GELU(approximate='none')\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed0851",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43ddf324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR (interpolated): 30.81 dB\n",
      "Average PSNR (super-resolved): 21.98 dB\n",
      "Average SSIM (interpolated): 0.9056\n",
      "Average SSIM (super-resolved): 0.7083\n"
     ]
    }
   ],
   "source": [
    "# Dataset for validation\n",
    "val_dataset = TIFFDataset('data/val/high-res', 'data/val/low-res', transform=transform)\n",
    "\n",
    "# Initialize metrics\n",
    "psnr_metric = PeakSignalNoiseRatio().to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "# Accumulators\n",
    "total_psnr_interpolated = 0\n",
    "total_psnr_super_resolved = 0\n",
    "total_ssim_interpolated = 0\n",
    "total_ssim_super_resolved = 0\n",
    "num_samples = len(val_dataset)\n",
    "\n",
    "# Loop over validation set\n",
    "for i in range(num_samples):\n",
    "    val_low_res, val_high_res = val_dataset[i]\n",
    "    val_low_res, val_high_res = val_low_res.to(device), val_high_res.to(device)\n",
    "\n",
    "    # Compute data range dynamically\n",
    "    data_range = val_high_res.max() - val_high_res.min()\n",
    "    ssim_metric.data_range = data_range\n",
    "\n",
    "    # Upsample low-res image\n",
    "\n",
    "    val_low_res_up = nn.functional.interpolate(val_low_res.unsqueeze(0), scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "    val_high_res = val_high_res  # Add batch dim\n",
    "\n",
    "    # val_super_res = model(val_low_res_up).detach()\n",
    "\n",
    "    val_super_res = model(val_low_res.unsqueeze(0)).detach()\n",
    "\n",
    "    # PSNR\n",
    "    # psnr_interp = psnr_metric(val_low_res_up, val_high_res).item()\n",
    "    psnr_interp = psnr_metric(val_low_res_up, val_high_res).item()\n",
    "    psnr_sr = psnr_metric(val_super_res, val_high_res).item()\n",
    "\n",
    "    # SSIM (data_range is now set in metric initialization)\n",
    "    # ssim_interp = ssim_metric(val_low_res_up, val_high_res).item()\n",
    "    ssim_interp = ssim_metric(val_low_res_up, val_high_res.unsqueeze(0)).item()\n",
    "    ssim_sr = ssim_metric(val_super_res, val_high_res.unsqueeze(0)).item()\n",
    "\n",
    "    # Accumulate\n",
    "    total_psnr_interpolated += psnr_interp\n",
    "    total_psnr_super_resolved += psnr_sr\n",
    "    total_ssim_interpolated += ssim_interp\n",
    "    total_ssim_super_resolved += ssim_sr\n",
    "\n",
    "# Averages\n",
    "avg_psnr_interp = total_psnr_interpolated / num_samples\n",
    "avg_psnr_sr = total_psnr_super_resolved / num_samples\n",
    "avg_ssim_interp = total_ssim_interpolated / num_samples\n",
    "avg_ssim_sr = total_ssim_super_resolved / num_samples\n",
    "\n",
    "# Print results\n",
    "print(f'Average PSNR (interpolated): {avg_psnr_interp:.2f} dB')\n",
    "print(f'Average PSNR (super-resolved): {avg_psnr_sr:.2f} dB')\n",
    "print(f'Average SSIM (interpolated): {avg_ssim_interp:.4f}')\n",
    "print(f'Average SSIM (super-resolved): {avg_ssim_sr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
