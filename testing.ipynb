{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d03dfd8",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe29d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.image.psnr import PeakSignalNoiseRatio\n",
    "from torchmetrics.image.ssim import StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82217412",
   "metadata": {},
   "source": [
    "Resource check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121f95f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86f9ac",
   "metadata": {},
   "source": [
    "Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db09e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 480\n"
     ]
    }
   ],
   "source": [
    "# Loading TIFF images for Super-resolution\n",
    "class TIFFDataset(Dataset):\n",
    "    def __init__(self, high_res_dir, low_res_dir, transform=None):\n",
    "        self.high_res_dir = high_res_dir\n",
    "        self.low_res_dir = low_res_dir\n",
    "        self.transform = transform\n",
    "        self.filenames = sorted([f for f in os.listdir(high_res_dir) if f.endswith('.tif')])\n",
    "    \n",
    "    # Get the number of samples in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    # Get the sample at the given index\n",
    "    def __getitem__(self, idx):\n",
    "        high_res_path = os.path.join(self.high_res_dir, self.filenames[idx])\n",
    "        low_res_path = os.path.join(self.low_res_dir, self.filenames[idx])\n",
    "\n",
    "        # Load images\n",
    "        high_res = Image.open(high_res_path)\n",
    "        low_res = Image.open(low_res_path)\n",
    "\n",
    "        # Resize low-res to 128x128 (ensuring correct input size)\n",
    "        low_res = low_res.resize((128, 128), Image.BICUBIC)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            high_res = self.transform(high_res)\n",
    "            low_res = self.transform(low_res)\n",
    "\n",
    "        return low_res, high_res  # Returning input-output pairs\n",
    "\n",
    "# Define a transform to convert images to PyTorch tensors\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "flip = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define a transform to convert images to PyTorch tensors with normalization\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "normalize_flip = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.RandomHorizontalFlip(p=1.0)\n",
    "])\n",
    "\n",
    "# Create the dataset for training images\n",
    "train_dataset = TIFFDataset('data/train/high-res', 'data/train/low-res', transform=transform)\n",
    "# Create the dataset for training images with flipping\n",
    "train_dataset_flip = TIFFDataset('data/train/high-res', 'data/train/low-res', transform=flip)\n",
    "\n",
    "# Combine the datasets\n",
    "train_dataset = torch.utils.data.ConcatDataset([train_dataset, train_dataset_flip])\n",
    "\n",
    "# Function to create data loader\n",
    "def create_loader(dataset, batch_size):\n",
    "    torch.manual_seed(0)  # For reproducibility\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print dataset size\n",
    "dataset_size = len(train_dataset)\n",
    "print('Number of images in the dataset:', dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251e0ce",
   "metadata": {},
   "source": [
    "Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testNet, self).__init__()\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        # 128 x 128 input\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # upscale to 256 x 256\n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # bicubic interpolation to 256 x 256 skip connection\n",
    "        self.bskip1 = nn.Upsample(scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "        # convolution to 256 x 256 combine with skip connection\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # upscale to 512 x 512\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # bicubic interpolation to 512 x 512 skip connection\n",
    "        self.bskip2 = nn.Upsample(scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "        # convolution to 512 x 512 combine with skip connection\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # downscale to 256 x 256\n",
    "        self.downconv1 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv7 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.gelu(x)\n",
    "\n",
    "        x_prev = self.bskip1(x)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.cat((x, x_prev), dim=1)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x_prev = self.bskip2(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.conv5(x)\n",
    "        x = torch.cat((x, x_prev), dim=1)\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.downconv1(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.gelu(self.conv8(x))\n",
    "        x = self.conv9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6168f76",
   "metadata": {},
   "source": [
    "Training Fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acba960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, criterion, train_loader, num_epoch):\n",
    "    avg_train_losses = []\n",
    "\n",
    "    for epoch in range(num_epoch):  # Loop over the dataset multiple times\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i, (x_tr_batch, y_tr_batch) in enumerate(train_loader):  # Loop over mini-batches\n",
    "            x_tr_batch, y_tr_batch = x_tr_batch.to(device), y_tr_batch.to(device)\n",
    "\n",
    "            # Upsample low-resolution input to 256x256\n",
    "            # x_tr_batch = torch.nn.functional.interpolate(x_tr_batch, scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "            opt.zero_grad()  # Delete previous gradients\n",
    "            y_hat_tr_batch = model(x_tr_batch)  # Forward pass\n",
    "            loss = criterion(y_hat_tr_batch, y_tr_batch)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            opt.step()  # Update weights\n",
    "            total_train_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Iteration {i+1}, Loss: {loss.item():.6f}')\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)  # Compute average loss\n",
    "        avg_train_losses.append(avg_train_loss)  # Store average loss\n",
    "\n",
    "    # Plot training loss\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(range(1, num_epoch + 1), avg_train_losses, label='training loss')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_yscale('log')  # Log scale for better visualization\n",
    "    ax.set_title('training loss')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4019070",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda96137",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10  # Number of complete images in each batch\n",
    "lr = 1e-3  # Learning rate\n",
    "num_epoch = 100  # Epochs\n",
    "\n",
    "# Model, criterion, and optimizer\n",
    "train_loader = create_loader(train_dataset, batch_size)\n",
    "model = testNet().to(device)  # Pick a model and move to GPU/CPU\n",
    "opt = optim.Adam(model.parameters(), lr=lr)  # Pick an optimizer\n",
    "criterion = nn.MSELoss()  # Pick a loss function\n",
    "\n",
    "# Train the model\n",
    "train_model(model, opt, criterion, train_loader, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed0851",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddf324",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TIFFDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset for validation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m val_dataset = \u001b[43mTIFFDataset\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mdata/val/high-res\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdata/val/low-res\u001b[39m\u001b[33m'\u001b[39m, transform=transform)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize metrics\u001b[39;00m\n\u001b[32m      5\u001b[39m psnr_metric = PeakSignalNoiseRatio().to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'TIFFDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset for validation\n",
    "val_dataset = TIFFDataset('data/val/high-res', 'data/val/low-res', transform=transform)\n",
    "\n",
    "# Initialize metrics\n",
    "psnr_metric = PeakSignalNoiseRatio().to(device)\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "\n",
    "# Accumulators\n",
    "total_psnr_interpolated = 0\n",
    "total_psnr_super_resolved = 0\n",
    "total_ssim_interpolated = 0\n",
    "total_ssim_super_resolved = 0\n",
    "num_samples = len(val_dataset)\n",
    "\n",
    "# Loop over validation set\n",
    "for i in range(num_samples):\n",
    "    val_low_res, val_high_res = val_dataset[i]\n",
    "    val_low_res, val_high_res = val_low_res.to(device), val_high_res.to(device)\n",
    "\n",
    "    # Compute data range dynamically\n",
    "    data_range = val_high_res.max() - val_high_res.min()\n",
    "    ssim_metric.data_range = data_range\n",
    "\n",
    "    # Upsample low-res image\n",
    "\n",
    "    val_low_res_up = torch.nn.functional.interpolate(val_low_res.unsqueeze(0), scale_factor=2, mode='bicubic', align_corners=False)\n",
    "\n",
    "    val_high_res = val_high_res.unsqueeze(0)  # Add batch dim\n",
    "\n",
    "    # val_super_res = model(val_low_res_up).detach()\n",
    "\n",
    "    val_super_res = model(val_low_res.unsqueeze(1)).detach()\n",
    "\n",
    "    # PSNR\n",
    "    # psnr_interp = psnr_metric(val_low_res_up, val_high_res).item()\n",
    "    psnr_interp = psnr_metric(val_low_res_up, val_high_res).item()\n",
    "    psnr_sr = psnr_metric(val_super_res, val_high_res).item()\n",
    "\n",
    "    # SSIM (data_range is now set in metric initialization)\n",
    "    # ssim_interp = ssim_metric(val_low_res_up, val_high_res).item()\n",
    "    ssim_interp = ssim_metric(val_low_res_up, val_high_res).item()\n",
    "    ssim_sr = ssim_metric(val_super_res, val_high_res).item()\n",
    "\n",
    "    # Accumulate\n",
    "    total_psnr_interpolated += psnr_interp\n",
    "    total_psnr_super_resolved += psnr_sr\n",
    "    total_ssim_interpolated += ssim_interp\n",
    "    total_ssim_super_resolved += ssim_sr\n",
    "\n",
    "# Averages\n",
    "avg_psnr_interp = total_psnr_interpolated / num_samples\n",
    "avg_psnr_sr = total_psnr_super_resolved / num_samples\n",
    "avg_ssim_interp = total_ssim_interpolated / num_samples\n",
    "avg_ssim_sr = total_ssim_super_resolved / num_samples\n",
    "\n",
    "# Print results\n",
    "print(f'Average PSNR (interpolated): {avg_psnr_interp:.2f} dB')\n",
    "print(f'Average PSNR (super-resolved): {avg_psnr_sr:.2f} dB')\n",
    "print(f'Average SSIM (interpolated): {avg_ssim_interp:.4f}')\n",
    "print(f'Average SSIM (super-resolved): {avg_ssim_sr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
